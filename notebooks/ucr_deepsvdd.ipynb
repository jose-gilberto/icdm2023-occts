{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict, List, Optional, Union, Tuple\n",
    "\n",
    "\n",
    "class BaseDataset(Dataset):\n",
    "    def __init__(self, x, y) -> None:\n",
    "        super().__init__()\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        \n",
    "        assert len(self.x) == len(self.y)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    \n",
    "    def __getitem__(self, index: int) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        return torch.from_numpy(self.x[index]).float(), torch.from_numpy(np.array([self.y[index]]))\n",
    "\n",
    "\n",
    "def same_padding1d(sequence_length: int, kernel_size: int, stride: Optional[int] = 1, dilation: Optional[int] = 1):\n",
    "    p = (sequence_length - 1) * stride + (kernel_size - 1) * dilation + 1 - sequence_length\n",
    "    return p // 2, p - p // 2\n",
    "\n",
    "\n",
    "class Pad1d(nn.ConstantPad1d):\n",
    "    def __init__(self, padding: Any, value: Optional[float] = 0.):\n",
    "        super().__init__(padding, value)\n",
    "\n",
    "\n",
    "class SameConv(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        kernel_size: Optional[Union[Tuple[int], int]] = 3,\n",
    "        stride: Optional[int] = 1,\n",
    "        dilation: Optional[int] = 1,\n",
    "        bias: Optional[bool] = False\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.kernel_size, self.stride, self.dilation = kernel_size, stride, dilation\n",
    "        # Create the conv module that will be used for same padding\n",
    "        self.conv1d_same = nn.Conv1d(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=out_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=stride,\n",
    "            dilation=dilation,\n",
    "            bias=bias\n",
    "        )\n",
    "        self.weight = self.conv1d_same.weight\n",
    "        if bias == True:\n",
    "            self.bias = self.conv1d_same.bias\n",
    "        self.pad = Pad1d\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        self.padding = same_padding1d(x.shape[-1], self.kernel_size, dilation=self.dilation) # Stride: will not be used on padding calculation\n",
    "        return self.conv1d_same(self.pad(self.padding)(x))\n",
    "\n",
    "\n",
    "def Conv1d(\n",
    "    in_channels: int,\n",
    "    out_channels: int,\n",
    "    kernel_size: Optional[Union[Tuple[int], int]] = None,\n",
    "    stride: Optional[int] = 1,\n",
    "    padding: Optional[Union[str, int]] = 'same',\n",
    "    dilation: Optional[int] = 1,\n",
    "    bias: Optional[bool] = False\n",
    ") -> nn.Module:\n",
    "    if padding == 'same':\n",
    "        if kernel_size % 2 == 1:\n",
    "            conv = nn.Conv1d(\n",
    "                in_channels=in_channels,\n",
    "                out_channels=out_channels,\n",
    "                kernel_size=kernel_size,\n",
    "                stride=stride,\n",
    "                padding=kernel_size // 2 * dilation,\n",
    "                dilation=dilation,\n",
    "                bias=bias\n",
    "            )\n",
    "        else:\n",
    "            conv = SameConv(\n",
    "                in_channels=in_channels,\n",
    "                out_channels=out_channels,\n",
    "                kernel_size=kernel_size,\n",
    "                stride=stride,\n",
    "                dilation=dilation,\n",
    "                bias=bias\n",
    "            )\n",
    "    else:\n",
    "        conv = nn.Conv1d(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=out_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=stride,\n",
    "            padding=padding,\n",
    "            dilation=dilation,\n",
    "            bias=bias\n",
    "        )\n",
    "\n",
    "    return conv\n",
    "\n",
    "\n",
    "class DeepSVDDAutoEncoder(pl.LightningModule):\n",
    "    def __init__(self, sequence_length: int, in_channels: int, representation_dim: int = 32) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.sequence_length = sequence_length\n",
    "        self.in_channels = in_channels\n",
    "        self.representation_dim = representation_dim\n",
    "\n",
    "        # --- Encoder --- #\n",
    "        self.encoder_conv1 = Conv1d(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=8,\n",
    "            kernel_size=5,\n",
    "            bias=False,\n",
    "        )\n",
    "        self.encoder_bn1 = nn.BatchNorm1d(num_features=8, eps=1e-04, affine=False)\n",
    "        self.encoder_conv2 = Conv1d(\n",
    "            in_channels=8,\n",
    "            out_channels=4,\n",
    "            kernel_size=5,\n",
    "            bias=False,\n",
    "        )\n",
    "        self.encoder_bn2 = nn.BatchNorm1d(num_features=4, eps=1e-04, affine=False)\n",
    "        self.encoder_linear = nn.Linear(self.sequence_length * 4, self.representation_dim, bias=False)\n",
    "        \n",
    "        # --- Decoder --- #\n",
    "        self.decoder_linear = nn.Linear(self.representation_dim, self.sequence_length * 4, bias=False)\n",
    "        self.decoder_conv1 = Conv1d(\n",
    "            in_channels=4,\n",
    "            out_channels=4,\n",
    "            kernel_size=5,\n",
    "            bias=False,\n",
    "        )\n",
    "        self.decoder_bn1 = nn.BatchNorm1d(num_features=4, eps=1e-04, affine=False)\n",
    "        self.decoder_conv2 = Conv1d(\n",
    "            in_channels=4,\n",
    "            out_channels=8,\n",
    "            kernel_size=5,\n",
    "            bias=False,\n",
    "        )\n",
    "        self.decoder_bn2 = nn.BatchNorm1d(num_features=8, eps=1e-04, affine=False)\n",
    "        self.decoder_conv3 = Conv1d(\n",
    "            in_channels=8,\n",
    "            out_channels=1,\n",
    "            kernel_size=5,\n",
    "            bias=False,\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        z = F.leaky_relu(self.encoder_bn1(self.encoder_conv1(x)))\n",
    "        z = F.leaky_relu(self.encoder_bn2(self.encoder_conv2(z)))\n",
    "        z = z.view(z.size(0), -1)\n",
    "        z = self.encoder_linear(z) # Final representation output for encoder\n",
    "\n",
    "        x_hat = self.decoder_linear(z)\n",
    "        x_hat = x_hat.view(z.size(0), 4, self.sequence_length)\n",
    "        x_hat = F.leaky_relu(self.decoder_bn1(self.decoder_conv1(x_hat)))\n",
    "        x_hat = F.leaky_relu(self.decoder_bn2(self.decoder_conv2(x_hat)))\n",
    "        x_hat = self.decoder_conv3(x_hat) # Final reconstruction output for decoder\n",
    "\n",
    "        return x_hat, z\n",
    "    \n",
    "    def configure_optimizers(self) -> Any:\n",
    "        # Set optimizer for the autoencoder task\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-4, weight_decay=1e-6, amsgrad=False)\n",
    "        # Set learning rate scheduler\n",
    "        scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[250], gamma=0.1)\n",
    "        return [optimizer], [scheduler]\n",
    "    \n",
    "    def training_step(self, batch: Tuple[torch.Tensor, torch.Tensor], batch_idx: int) -> torch.Tensor:\n",
    "        x, y = batch\n",
    "        x_hat, z = self(x)\n",
    "        \n",
    "        loss = torch.sum((x_hat - x) ** 2, dim=tuple(range(1, x_hat.dim())))\n",
    "        loss = torch.mean(loss)\n",
    "        \n",
    "        self.log('train_loss', loss, prog_bar=True, on_step=False, on_epoch=True)\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    def test_step(self, batch: Tuple[torch.Tensor, torch.Tensor], batch_idx: int) -> List[Dict[str, Any]]:\n",
    "        x, y = batch\n",
    "        x_hat, z = self(x)\n",
    "\n",
    "        loss = torch.sum((x_hat - x) ** 2, dim=tuple(range(1, x_hat.dim())))\n",
    "        loss = torch.mean(loss)\n",
    "        \n",
    "        self.log('test_loss', loss, prog_bar=True, on_step=False, on_epoch=True)\n",
    "\n",
    "        return\n",
    "\n",
    "\n",
    "class DeepSVDD(pl.LightningModule):\n",
    "    def __init__(self, sequence_length: int, in_channels: int, representation_dim: int = 32) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.sequence_length = sequence_length\n",
    "        self.in_channels = in_channels\n",
    "        self.representation_dim = representation_dim\n",
    "        \n",
    "        self.R = torch.tensor(0.0, device=self.device)\n",
    "        self.nu = 0.1\n",
    "        self.center = None\n",
    "\n",
    "        # --- Encoder --- #\n",
    "        self.encoder_conv1 = Conv1d(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=8,\n",
    "            kernel_size=5,\n",
    "            bias=False,\n",
    "        )\n",
    "        self.encoder_bn1 = nn.BatchNorm1d(num_features=8, eps=1e-04, affine=False)\n",
    "        self.encoder_conv2 = Conv1d(\n",
    "            in_channels=8,\n",
    "            out_channels=4,\n",
    "            kernel_size=5,\n",
    "            bias=False,\n",
    "        )\n",
    "        self.encoder_bn2 = nn.BatchNorm1d(num_features=4, eps=1e-04, affine=False)\n",
    "        self.encoder_linear = nn.Linear(self.sequence_length * 4, self.representation_dim, bias=False)\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        z = F.leaky_relu(self.encoder_bn1(self.encoder_conv1(x)))\n",
    "        z = F.leaky_relu(self.encoder_bn2(self.encoder_conv2(z)))\n",
    "        z = z.view(z.size(0), -1)\n",
    "        z = self.encoder_linear(z)\n",
    "\n",
    "        return z\n",
    "\n",
    "    def init_center(self, loader: DataLoader, eps: Optional[float] = 0.01) -> torch.Tensor:\n",
    "        n_samples = 0\n",
    "        center = torch.zeros(self.representation_dim, device=self.device)\n",
    "\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            for (x, y) in loader:\n",
    "                x = x.to(self.device)\n",
    "                z = self(x)\n",
    "\n",
    "                n_samples += z.shape[0]\n",
    "                center += torch.sum(z, dim=0)\n",
    "\n",
    "        center /= n_samples\n",
    "\n",
    "        center[(abs(center) < eps) & (center < 0)] = -eps\n",
    "        center[(abs(center) < eps) & (center > 0)] = eps\n",
    "        \n",
    "        return center\n",
    "    \n",
    "    def get_radius(self, distance: torch.Tensor, nu: float):\n",
    "        return np.quantile(np.sqrt(distance.clone().data.cpu().numpy()), 1 - nu)\n",
    "\n",
    "    def configure_optimizers(self) -> Any:\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-4, weight_decay=1e-6, amsgrad=False)\n",
    "        scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[150], gamma=0.1)\n",
    "        return [optimizer], [scheduler]\n",
    "    \n",
    "    def training_step(self, batch: Tuple[torch.Tensor, torch.Tensor], batch_idx: int) -> torch.Tensor:\n",
    "        x, y = batch\n",
    "        z = self(x)\n",
    "        \n",
    "        distance = torch.sum((z - self.center) ** 2, dim=1)\n",
    "        scores = distance - self.R ** 2\n",
    "        loss = self.R ** 2 + (1 / self.nu) * torch.mean(torch.max(torch.zeros_like(scores), scores))\n",
    "\n",
    "        self.log('train_loss', loss, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        \n",
    "        if self.current_epoch >= 10:\n",
    "            self.R.data = torch.tensor(self.get_radius(distance, self.nu), device=self.device)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def test_step(self, batch: Tuple[torch.Tensor, torch.Tensor], batch_idx: int) -> List[Dict[str, Any]]:\n",
    "        x, y = batch\n",
    "        z = self(x)\n",
    "\n",
    "        distance = torch.sum((z - self.center) ** 2, dim=1)\n",
    "        scores = distance - self.R ** 2\n",
    "\n",
    "        preds = torch.max(torch.zeros_like(scores), scores).tolist()\n",
    "        preds = np.array([1 if pred > 0 else -1 for pred in preds])\n",
    "\n",
    "        self.log('accuracy_score', accuracy_score(preds, y.cpu().numpy()))\n",
    "        self.log('f1', f1_score(preds, y.cpu().numpy()))\n",
    "        self.log('recall', recall_score(preds, y.cpu().numpy()))\n",
    "        self.log('precision', precision_score(preds, y.cpu().numpy()))\n",
    "\n",
    "        return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "UCR_DATASETS = [\n",
    "    'Adiac',\n",
    "    'ArrowHead',\n",
    "    'Beef',\n",
    "    'BeetleFly',\n",
    "    'BirdChicken',\n",
    "    'Car',\n",
    "    'CBF',\n",
    "    'ChlorineConcentration',\n",
    "    'CinCECGTorso',\n",
    "    'Coffee',\n",
    "    'Computers',\n",
    "    'CricketX',\n",
    "    'CricketY',\n",
    "    'CricketZ',\n",
    "    'DiatomSizeReduction',\n",
    "    'DistalPhalanxOutlineAgeGroup',\n",
    "    'DistalPhalanxOutlineCorrect',\n",
    "    'DistalPhalanxTW',\n",
    "    'Earthquakes',\n",
    "    'ECG200',\n",
    "    'ECG5000',\n",
    "    'ECGFiveDays',\n",
    "    'ElectricDevices',\n",
    "    'FaceAll',\n",
    "    'FaceFour',\n",
    "    'FacesUCR',\n",
    "    'FiftyWords',\n",
    "    'Fish',\n",
    "    'FordA',\n",
    "    'FordB',\n",
    "    'GunPoint',\n",
    "    'Ham',\n",
    "    'HandOutlines',\n",
    "    'Haptics',\n",
    "    'Herring',\n",
    "    'InlineSkate',\n",
    "    'InsectWingbeatSound',\n",
    "    'ItalyPowerDemand',\n",
    "    'LargeKitchenAppliances',\n",
    "    'Lightning2',\n",
    "    'Lightning7',\n",
    "    'Mallat',\n",
    "    'Meat',\n",
    "    'MedicalImages',\n",
    "    'MiddlePhalanxOutlineAgeGroup',\n",
    "    'MiddlePhalanxOutlineCorrect',\n",
    "    'MiddlePhalanxTW',\n",
    "    'MoteStrain',\n",
    "    'NonInvasiveFetalECGThorax1',\n",
    "    'NonInvasiveFetalECGThorax2',\n",
    "    'OliveOil',\n",
    "    'OSULeaf',\n",
    "    'PhalangesOutlinesCorrect',\n",
    "    'Phoneme',\n",
    "    'Plane',\n",
    "    'ProximalPhalanxOutlineAgeGroup',\n",
    "    'ProximalPhalanxOutlineCorrect',\n",
    "    'ProximalPhalanxTW',\n",
    "    'RefrigerationDevices',\n",
    "    'ScreenType',\n",
    "    'ShapeletSim',\n",
    "    'ShapesAll',\n",
    "    'SmallKitchenAppliances',\n",
    "    'SonyAIBORobotSurface1',\n",
    "    'SonyAIBORobotSurface2',\n",
    "    'StarLightCurves',\n",
    "    'Strawberry',\n",
    "    'SwedishLeaf',\n",
    "    'Symbols',\n",
    "    'SyntheticControl',\n",
    "    'ToeSegmentation1',\n",
    "    'ToeSegmentation2',\n",
    "    'Trace',\n",
    "    'TwoLeadECG',\n",
    "    'TwoPatterns',\n",
    "    'UWaveGestureLibraryAll',\n",
    "    'UWaveGestureLibraryX',\n",
    "    'UWaveGestureLibraryY',\n",
    "    'UWaveGestureLibraryZ',\n",
    "    'Wafer',\n",
    "    'Wine',\n",
    "    'WordSynonyms',\n",
    "    'Worms',\n",
    "    'WormsTwoClass',\n",
    "    'Yoga',\n",
    "    'ACSF1',\n",
    "    'BME',\n",
    "    'Chinatown',\n",
    "    'Crop',\n",
    "    'EOGHorizontalSignal',\n",
    "    'EOGVerticalSignal',\n",
    "    'EthanolLevel',\n",
    "    'FreezerRegularTrain',\n",
    "    'FreezerSmallTrain',\n",
    "    'Fungi',\n",
    "    'GunPointAgeSpan',\n",
    "    'GunPointMaleVersusFemale',\n",
    "    'GunPointOldVersusYoung',\n",
    "    'HouseTwenty',\n",
    "    'InsectEPGRegularTrain',\n",
    "    'InsectEPGSmallTrain',\n",
    "    'MixedShapesRegularTrain',\n",
    "    'MixedShapesSmallTrain',\n",
    "    'PigAirwayPressure',\n",
    "    'PigArtPressure',\n",
    "    'PigCVP',\n",
    "    'PowerCons',\n",
    "    'Rock',\n",
    "    'SemgHandGenderCh2',\n",
    "    'SemgHandMovementCh2',\n",
    "    'SemgHandSubjectCh2',\n",
    "    'SmoothSubspace',\n",
    "    'UMD'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {\n",
    "    'dataset': [],\n",
    "    'model': [],\n",
    "    'label': [],\n",
    "    'accuracy': [],\n",
    "    'f1': [],\n",
    "    'recall': [],\n",
    "    'precision': [],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3060') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name           | Type        | Params\n",
      "------------------------------------------------\n",
      "0  | encoder_conv1  | Conv1d      | 40    \n",
      "1  | encoder_bn1    | BatchNorm1d | 0     \n",
      "2  | encoder_conv2  | Conv1d      | 160   \n",
      "3  | encoder_bn2    | BatchNorm1d | 0     \n",
      "4  | encoder_linear | Linear      | 22.5 K\n",
      "5  | decoder_linear | Linear      | 22.5 K\n",
      "6  | decoder_conv1  | Conv1d      | 80    \n",
      "7  | decoder_bn1    | BatchNorm1d | 0     \n",
      "8  | decoder_conv2  | Conv1d      | 160   \n",
      "9  | decoder_bn2    | BatchNorm1d | 0     \n",
      "10 | decoder_conv3  | Conv1d      | 40    \n",
      "------------------------------------------------\n",
      "45.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "45.5 K    Total params\n",
      "0.182     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting experiments with Adiac dataset...\n",
      "\tClassifying the label 1.0...\n",
      "Epoch 349: 100%|██████████| 1/1 [00:00<00:00, 201.35it/s, v_num=14, train_loss=7.590]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=350` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 349: 100%|██████████| 1/1 [00:00<00:00, 89.40it/s, v_num=14, train_loss=7.590] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3060') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name           | Type        | Params\n",
      "-----------------------------------------------\n",
      "0 | encoder_conv1  | Conv1d      | 40    \n",
      "1 | encoder_bn1    | BatchNorm1d | 0     \n",
      "2 | encoder_conv2  | Conv1d      | 160   \n",
      "3 | encoder_bn2    | BatchNorm1d | 0     \n",
      "4 | encoder_linear | Linear      | 22.5 K\n",
      "-----------------------------------------------\n",
      "22.7 K    Trainable params\n",
      "0         Non-trainable params\n",
      "22.7 K    Total params\n",
      "0.091     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 349: 100%|██████████| 1/1 [00:00<00:00, 203.86it/s, v_num=15, train_loss=0.0448]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=350` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 349: 100%|██████████| 1/1 [00:00<00:00, 112.17it/s, v_num=15, train_loss=0.0448]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3060') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing DataLoader 0: 100%|██████████| 25/25 [00:00<00:00, 173.22it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "     accuracy_score         0.1585677749360614\n",
      "           f1              0.016505835070601133\n",
      "        precision           0.12276214833759591\n",
      "         recall            0.008853039543576628\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'dataset'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 54\u001b[0m\n\u001b[1;32m     50\u001b[0m trainer_deepsvdd\u001b[39m.\u001b[39mfit(deepsvdd, train_dataloaders\u001b[39m=\u001b[39mtrain_loader)\n\u001b[1;32m     52\u001b[0m results \u001b[39m=\u001b[39m trainer_deepsvdd\u001b[39m.\u001b[39mtest(deepsvdd, dataloaders\u001b[39m=\u001b[39mtest_loader)[\u001b[39m0\u001b[39m]\n\u001b[0;32m---> 54\u001b[0m results[\u001b[39m'\u001b[39;49m\u001b[39mdataset\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39mappend(dataset)\n\u001b[1;32m     55\u001b[0m results[\u001b[39m'\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mappend(\u001b[39m'\u001b[39m\u001b[39mdeepsvdd\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     56\u001b[0m results[\u001b[39m'\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mappend(label)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'dataset'"
     ]
    }
   ],
   "source": [
    "for dataset in UCR_DATASETS:\n",
    "    print(f'Starting experiments with {dataset} dataset...')\n",
    "    # Load the data from .tsv files\n",
    "    train_data = np.genfromtxt(f'../data/ucr/{dataset}/{dataset}_TRAIN.tsv')\n",
    "    x_train, y_train = train_data[:, 1:], train_data[:, 0]\n",
    "    \n",
    "    test_data = np.genfromtxt(f'../data/ucr/{dataset}/{dataset}_TEST.tsv')\n",
    "    x_test, y_test = test_data[:, 1:], test_data[:, 0]\n",
    "    \n",
    "    unique_labels = np.unique(y_train)\n",
    "    for label in unique_labels:\n",
    "        print(f'\\tClassifying the label {label}...')\n",
    "        # Filter samples from positive label\n",
    "        x_train_ = x_train[y_train == label]\n",
    "        y_train_ = y_train[y_train == label]\n",
    "\n",
    "        y_test_ = np.array([1 if y_true == label else -1 for y_true in y_test])\n",
    "        \n",
    "        # Apply z normalization\n",
    "        std_ = x_train_.std(axis=1, keepdims=True)\n",
    "        std_[std_ == 0] = 1.0\n",
    "        x_train_ = (x_train_ - x_train_.mean(axis=1, keepdims=True)) / std_\n",
    "        \n",
    "        std_ = x_test.std(axis=1, keepdims=True)\n",
    "        std_[std_ == 0] = 1.0\n",
    "        x_test = (x_test - x_test.mean(axis=1, keepdims=True)) / std_\n",
    "    \n",
    "        \n",
    "        x_train_ = np.expand_dims(x_train_, axis=1)\n",
    "        x_test = np.expand_dims(x_test, axis=1)\n",
    "        \n",
    "        train_set = BaseDataset(x=x_train_, y=y_train_)\n",
    "        test_set = BaseDataset(x=x_test, y=y_test_)\n",
    "        \n",
    "        train_loader = DataLoader(train_set, batch_size=16)\n",
    "        test_loader = DataLoader(test_set, batch_size=16)\n",
    "\n",
    "        # Train the autoencoder to learn the data representation over the new space\n",
    "        autoencoder = DeepSVDDAutoEncoder(x_train_.shape[-1], in_channels=1)\n",
    "        trainer = pl.Trainer(max_epochs=350, accelerator='gpu', devices=-1)\n",
    "        trainer.fit(autoencoder, train_dataloaders=train_loader)\n",
    "        \n",
    "        deepsvdd = DeepSVDD(sequence_length=x_train_.shape[-1], in_channels=1)\n",
    "        deepsvdd.to(torch.device('cuda'))\n",
    "\n",
    "        center = deepsvdd.init_center(train_loader)\n",
    "        deepsvdd.center = center\n",
    "\n",
    "        trainer_deepsvdd = pl.Trainer(max_epochs=350, accelerator='gpu', devices=-1)\n",
    "        trainer_deepsvdd.fit(deepsvdd, train_dataloaders=train_loader)\n",
    "        \n",
    "        metrics = trainer_deepsvdd.test(deepsvdd, dataloaders=test_loader)[0]\n",
    "        \n",
    "        results['dataset'].append(dataset)\n",
    "        results['model'].append('deepsvdd')\n",
    "        results['label'].append(label)\n",
    "        results['accuracy'].append(metrics['accuracy_score'].item())\n",
    "        results['f1'].append(metrics['f1'].item())\n",
    "        results['recall'].append(metrics['recall'].item())\n",
    "        results['precision'].append(metrics['precision'].item())\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
