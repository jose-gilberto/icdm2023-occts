{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict, List, Optional, Union, Tuple\n",
    "\n",
    "from pytorch_lightning.utilities.types import STEP_OUTPUT\n",
    "\n",
    "\n",
    "def same_padding1d(sequence_length: int, kernel_size: int, stride: Optional[int] = 1, dilation: Optional[int] = 1):\n",
    "    p = (sequence_length - 1) * stride + (kernel_size - 1) * dilation + 1 - sequence_length\n",
    "    return p // 2, p - p // 2\n",
    "\n",
    "\n",
    "class Pad1d(nn.ConstantPad1d):\n",
    "    def __init__(self, padding: Any, value: Optional[float] = 0.):\n",
    "        super().__init__(padding, value)\n",
    "\n",
    "\n",
    "class SameConv(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        kernel_size: Optional[Union[Tuple[int], int]] = 3,\n",
    "        stride: Optional[int] = 1,\n",
    "        dilation: Optional[int] = 1,\n",
    "        bias: Optional[bool] = False\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.kernel_size, self.stride, self.dilation = kernel_size, stride, dilation\n",
    "        # Create the conv module that will be used for same padding\n",
    "        self.conv1d_same = nn.Conv1d(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=out_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=stride,\n",
    "            dilation=dilation,\n",
    "            bias=bias\n",
    "        )\n",
    "        self.weight = self.conv1d_same.weight\n",
    "        if bias == True:\n",
    "            self.bias = self.conv1d_same.bias\n",
    "        self.pad = Pad1d\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        self.padding = same_padding1d(x.shape[-1], self.kernel_size, dilation=self.dilation) # Stride: will not be used on padding calculation\n",
    "        return self.conv1d_same(self.pad(self.padding)(x))\n",
    "\n",
    "\n",
    "def Conv1d(\n",
    "    in_channels: int,\n",
    "    out_channels: int,\n",
    "    kernel_size: Optional[Union[Tuple[int], int]] = None,\n",
    "    stride: Optional[int] = 1,\n",
    "    padding: Optional[Union[str, int]] = 'same',\n",
    "    dilation: Optional[int] = 1,\n",
    "    bias: Optional[bool] = False\n",
    ") -> nn.Module:\n",
    "    if padding == 'same':\n",
    "        if kernel_size % 2 == 1:\n",
    "            conv = nn.Conv1d(\n",
    "                in_channels=in_channels,\n",
    "                out_channels=out_channels,\n",
    "                stride=stride,\n",
    "                padding=kernel_size // 2 * dilation,\n",
    "                dilation=dilation,\n",
    "                bias=bias\n",
    "            )\n",
    "        else:\n",
    "            conv = SameConv(\n",
    "                in_channels=in_channels,\n",
    "                out_channels=out_channels,\n",
    "                kernel_size=kernel_size,\n",
    "                stride=stride,\n",
    "                dilation=dilation,\n",
    "                bias=bias\n",
    "            )\n",
    "    else:\n",
    "        conv = nn.Conv1d(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=out_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=stride,\n",
    "            padding=padding,\n",
    "            dilation=dilation,\n",
    "            bias=bias\n",
    "        )\n",
    "\n",
    "    return conv\n",
    "\n",
    "\n",
    "class DeepSVDDAutoEncoder(pl.LightningModule):\n",
    "    def __init__(self, sequence_length: int, in_channels: int, representation_dim: int = 32) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.sequence_length = sequence_length\n",
    "        self.in_channels = in_channels\n",
    "        self.representation_dim = representation_dim\n",
    "\n",
    "        # --- Encoder --- #\n",
    "        self.encoder_conv1 = Conv1d(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=8,\n",
    "            kernel_size=5,\n",
    "            bias=False,\n",
    "        )\n",
    "        self.encoder_bn1 = nn.BatchNorm1d(num_features=8, eps=1e-04, affine=False)\n",
    "        self.encoder_conv2 = Conv1d(\n",
    "            in_channels=8,\n",
    "            out_channels=4,\n",
    "            kernel_size=5,\n",
    "            bias=False,\n",
    "        )\n",
    "        self.encoder_bn2 = nn.BatchNorm1d(num_features=4, eps=1e-04, affine=False)\n",
    "        self.encoder_linear = nn.Linear(self.sequence_length * 4, self.representation_dim, bias=False)\n",
    "        \n",
    "        # --- Decoder --- #\n",
    "        self.decoder_linear = nn.Linear(self.representation_dim, self.sequence_length * 4, bias=False)\n",
    "        self.decoder_conv1 = Conv1d(\n",
    "            in_channels=4,\n",
    "            out_channels=4,\n",
    "            kernel_size=5,\n",
    "            bias=False,\n",
    "        )\n",
    "        self.decoder_bn1 = nn.BatchNorm1d(num_features=4, eps=1e-04, affine=False)\n",
    "        self.decoder_conv2 = Conv1d(\n",
    "            in_channels=4,\n",
    "            out_channels=8,\n",
    "            kernel_size=5,\n",
    "            bias=False,\n",
    "        )\n",
    "        self.decoder_bn2 = nn.BatchNorm1d(num_features=8, eps=1e-04, affine=False)\n",
    "        self.decoder_conv3 = Conv1d(\n",
    "            in_channels=8,\n",
    "            out_channels=1,\n",
    "            kernel_size=5,\n",
    "            bias=False,\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        z = F.leaky_relu(self.encoder_bn1(self.encoder_conv1(x)))\n",
    "        z = F.leaky_relu(self.encoder_bn2(self.encoder_conv2(z)))\n",
    "        z = z.view(z.size(0), -1)\n",
    "        z = self.encoder_linear(z) # Final representation output for encoder\n",
    "\n",
    "        x_hat = self.decoder_linear(z)\n",
    "        x_hat = x_hat.view(z.size(0), 4, self.sequence_length)\n",
    "        x_hat = F.leaky_relu(self.decoder_bn1(self.decoder_conv1(x_hat)))\n",
    "        x_hat = F.leaky_relu(self.decoder_bn2(self.decoder_conv2(x_hat)))\n",
    "        x_hat = self.decoder_conv3(x_hat) # Final reconstruction output for decoder\n",
    "\n",
    "        return x_hat, z\n",
    "    \n",
    "    def configure_optimizers(self) -> Any:\n",
    "        # Set optimizer for the autoencoder task\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-4, weight_decay=1e-6, amsgrad=False)\n",
    "        # Set learning rate scheduler\n",
    "        scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[250], gamma=0.1)\n",
    "        return [optimizer], [scheduler]\n",
    "    \n",
    "    def training_step(self, batch: Tuple[torch.Tensor, torch.Tensor], batch_idx: int) -> torch.Tensor:\n",
    "        x, y = batch\n",
    "        x_hat, z = self(x)\n",
    "        \n",
    "        loss = torch.sum((x_hat - x) ** 2, dim=tuple(range(1, x_hat.dim())))\n",
    "        loss = torch.mean(loss)\n",
    "        \n",
    "        self.log('train_loss', loss, prog_bar=True, on_step=False, on_epoch=True)\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    def test_step(self, batch: Tuple[torch.Tensor, torch.Tensor], batch_idx: int) -> List[Dict[str, Any]]:\n",
    "        x, y = batch\n",
    "        x_hat, z = self(x)\n",
    "\n",
    "        loss = torch.sum((x_hat - x) ** 2, dim=tuple(range(1, x_hat.dim())))\n",
    "        loss = torch.mean(loss)\n",
    "        \n",
    "        self.log('test_loss', loss, prog_bar=True, on_step=False, on_epoch=True)\n",
    "\n",
    "        return\n",
    "\n",
    "\n",
    "class DeepSVDD(pl.LightningModule):\n",
    "    def __init__(self, sequence_length: int, in_channels: int, representation_dim: int = 32) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.sequence_length = sequence_length\n",
    "        self.in_channels = in_channels\n",
    "        self.representation_dim = representation_dim\n",
    "        \n",
    "        self.R = torch.tensor(0.0, device=self.device)\n",
    "        self.nu = 0.1\n",
    "\n",
    "        # --- Encoder --- #\n",
    "        self.encoder_conv1 = Conv1d(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=8,\n",
    "            kernel_size=5,\n",
    "            bias=False,\n",
    "        )\n",
    "        self.encoder_bn1 = nn.BatchNorm1d(num_features=8, eps=1e-04, affine=False)\n",
    "        self.encoder_conv2 = Conv1d(\n",
    "            in_channels=8,\n",
    "            out_channels=4,\n",
    "            kernel_size=5,\n",
    "            bias=False,\n",
    "        )\n",
    "        self.encoder_bn2 = nn.BatchNorm1d(num_features=4, eps=1e-04, affine=False)\n",
    "        self.encoder_linear = nn.Linear(self.sequence_length * 4, self.representation_dim, bias=False)\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        z = F.leaky_relu(self.encoder_bn1(self.encoder_conv1(x)))\n",
    "        z = F.leaky_relu(self.encoder_bn2(self.encoder_conv2(z)))\n",
    "        z = z.view(z.size(0), -1)\n",
    "        z = self.encoder_linear(z)\n",
    "\n",
    "        return z\n",
    "\n",
    "    def init_center(self, loader: DataLoader, eps: Optional[float] = 0.01) -> torch.Tensor:\n",
    "        n_samples = 0\n",
    "        center = torch.zeros(self.representation_dim, device=self.device)\n",
    "\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            for (x, y) in loader:\n",
    "                x = x.to(self.device)\n",
    "                z = self(x)\n",
    "\n",
    "                n_samples += z.shape[0]\n",
    "                center += torch.sum(z, dim=0)\n",
    "\n",
    "        center /= n_samples\n",
    "\n",
    "        center[(abs(center) < eps) & (center < 0)] = -eps\n",
    "        center[(abs(center) < eps) & (center > 0)] = eps\n",
    "        \n",
    "        return center\n",
    "    \n",
    "    def get_radius(self, distance: torch.Tensor, nu: float):\n",
    "        return np.quantile(np.sqrt(distance.clone().data.cpu().numpy()), 1 - nu)\n",
    "\n",
    "    def configure_optimizers(self) -> Any:\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-4, weight_decay=1e-6, amsgrad=False)\n",
    "        scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[150], gamma=0.1)\n",
    "        return [optimizer], [scheduler]\n",
    "    \n",
    "    def training_step(self, batch: Tuple[torch.Tensor, torch.Tensor], batch_idx: int) -> torch.Tensor:\n",
    "        x, y = batch\n",
    "        z = self(x)\n",
    "        \n",
    "        distance = torch.sum((z - self.center) ** 2, dim=1)\n",
    "        scores = distance - self.R ** 2\n",
    "        loss = self.R ** 2 + (1 / self.nu) * torch.mean(torch.max(torch.zeros_like(scores), scores))\n",
    "        \n",
    "        self.log('train_loss', loss, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        \n",
    "        if self.current_epoch >= 10:\n",
    "            self.R.data = torch.tensor(self.get_radius(distance, self.nu), device=self.device)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def test_step(self, batch: Tuple[torch.Tensor, torch.Tensor], batch_idx: int) -> List[Dict[str, Any]]:\n",
    "        return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
